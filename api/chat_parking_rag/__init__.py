import azure.functions as func
import logging
import json
import os
from openai import AzureOpenAI
from azure.cosmos import CosmosClient
from datetime import datetime, timezone
import pytz
import re

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
AZURE_OPENAI_ENDPOINT = os.environ["AZURE_OPENAI_ENDPOINT"]
AZURE_OPENAI_API_KEY = os.environ["AZURE_OPENAI_API_KEY"]
AZURE_OPENAI_DEPLOYMENT = os.environ["AZURE_OPENAI_DEPLOYMENT"]
OPENAI_API_VERSION = os.environ["OPENAI_API_VERSION"]
OPENAI_GPT_MODEL = os.environ["OPENAI_GPT_MODEL"]

COSMOS_ENDPOINT = os.environ["COSMOS_DB_ENDPOINT"]
COSMOS_KEY = os.environ["COSMOS_DB_KEY"]
COSMOS_DB = os.environ["COSMOS_DB_NAME"]
COSMOS_PARKING_CONTAINER = os.environ["COSMOS_DB_CONTAINER"]  # ì£¼ì°¨ì¥ ì»¨í…Œì´ë„ˆ
COSMOS_FACILITY_CONTAINER = os.environ["COSMOS_FACILITY_CONTAINER"] # ì‹œì„¤ ì»¨í…Œì´ë„ˆ
COSMOS_FLIGHT_CONTAINER = os.environ["COSMOS_FLIGHT_CONTAINER"]  # í•­ê³µí¸ ì»¨í…Œì´ë„ˆ

APPLICATION_JSON = "application/json"

# í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
openai_client = AzureOpenAI(
    azure_endpoint=AZURE_OPENAI_ENDPOINT,
    api_key=AZURE_OPENAI_API_KEY,
    api_version=OPENAI_API_VERSION
)

cosmos_client = CosmosClient(COSMOS_ENDPOINT, COSMOS_KEY)
db_client = cosmos_client.get_database_client(COSMOS_DB)
parking_container = db_client.get_container_client(COSMOS_PARKING_CONTAINER)
facility_container = db_client.get_container_client(COSMOS_FACILITY_CONTAINER)
flight_container = db_client.get_container_client(COSMOS_FLIGHT_CONTAINER)

# í•­ê³µí¸ ë²ˆí˜¸ ì¶”ì¶œ í•¨ìˆ˜ ì¶”ê°€
def extract_flight_number(text):
    """í…ìŠ¤íŠ¸ì—ì„œ í•­ê³µí¸ ë²ˆí˜¸ ì¶”ì¶œ"""
    # í•­ê³µí¸ ë²ˆí˜¸ íŒ¨í„´: ì˜ë¬¸ 2-3ìë¦¬ + ìˆ«ì 3-4ìë¦¬
    flight_patterns = [
        r'\b[A-Z]{2}[0-9]{3,4}\b',  # KE123, AF5369
        r'\b[0-9][A-Z][0-9]{3,4}\b',  # 7C1301
        r'\b[A-Z][0-9][A-Z][0-9]{3,4}\b'  # íŠ¹ìˆ˜ íŒ¨í„´
    ]
    
    for pattern in flight_patterns:
        matches = re.findall(pattern, text.upper())
        if matches:
            return matches[0]
    
    return None

# ì§ˆë¬¸ ë¶„ë¥˜ í•¨ìˆ˜ ê°œì„ 
def classify_question(user_query):
    """ì‚¬ìš©ì ì§ˆë¬¸ì„ ì¹´í…Œê³ ë¦¬ë³„ë¡œ ë¶„ë¥˜"""
    # ë¨¼ì € í•­ê³µí¸ ë²ˆí˜¸ ì¶”ì¶œ ì‹œë„
    flight_number = extract_flight_number(user_query)
    
    messages = [
        {"role": "system", "content": """
            ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë‹¤ìŒ ì¹´í…Œê³ ë¦¬ ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•˜ì„¸ìš”:
            
            1. "parking" - ì£¼ì°¨ì¥ ê´€ë ¨ ì§ˆë¬¸ (í˜¼ì¡ë„, ì”ì—¬ê³µê°„, ì£¼ì°¨ë¹„ ë“±)
            2. "facility" - ê³µí•­ ì‹œì„¤ ê´€ë ¨ ì§ˆë¬¸ (í™˜ì „ì†Œ, ì‹ë‹¹, ì‡¼í•‘, í¸ì˜ì‹œì„¤ ë“±)
            3. "flight" - í•­ê³µí¸ ê´€ë ¨ ì§ˆë¬¸ (ì¶œë°œ/ë„ì°© ì‹œê°„, ê²Œì´íŠ¸, ë‚ ì”¨, í•­ê³µì‚¬ ë“±)
            4. "general" - ì—¬í–‰ ì¤€ë¹„ë¬¼, ì¼ë°˜ì ì¸ ê³µí•­ ì´ìš© íŒ ë“±
            5. "mixed" - ì—¬ëŸ¬ ì¹´í…Œê³ ë¦¬ê°€ ì„ì¸ ë³µí•© ì§ˆë¬¸
            
            í•­ê³µí¸ ë²ˆí˜¸ë‚˜ "KE1234", "7C1301", "AF5369" ê°™ì€ í˜•íƒœê°€ ìˆìœ¼ë©´ ê±°ì˜ í™•ì‹¤íˆ "flight"ì…ë‹ˆë‹¤.
            "ì‹ë‹¹", "í•œì‹", "ì¤‘ì‹", "ì¼ì‹", "ì¹´í˜", "í¸ì˜ì ", "ì‡¼í•‘", "ë©´ì„¸ì ", "í™˜ì „" ë“±ì´ ìˆìœ¼ë©´ "facility"ì…ë‹ˆë‹¤.
            
            JSON í˜•íƒœë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:
            {"category": "ë¶„ë¥˜ê²°ê³¼", "confidence": 0.95}
        """},
        {"role": "user", "content": user_query}
    ]
    
    try:
        response = openai_client.chat.completions.create(
            model=OPENAI_GPT_MODEL,
            messages=messages,
            response_format={"type": "json_object"},
            temperature=0.1
        )
        
        result = json.loads(response.choices[0].message.content)
        # ì¶”ì¶œëœ í•­ê³µí¸ ë²ˆí˜¸ê°€ ìˆìœ¼ë©´ ì¶”ê°€
        if flight_number:
            result["flight_number"] = flight_number
            result["category"] = "flight"  # í•­ê³µí¸ ë²ˆí˜¸ê°€ ìˆìœ¼ë©´ ê°•ì œë¡œ flight ì¹´í…Œê³ ë¦¬
        else:
            result["flight_number"] = None
            
        logging.info(f"ì§ˆë¬¸ ë¶„ë¥˜ ê²°ê³¼: {result}")
        return result
    except Exception as e:
        logging.error(f"ì§ˆë¬¸ ë¶„ë¥˜ ì˜¤ë¥˜: {str(e)}")
        return {"category": "general", "confidence": 0.5, "flight_number": flight_number}

# ê¸°ì¡´ ì£¼ì°¨ì¥ ê´€ë ¨ í•¨ìˆ˜ë“¤
def get_entities(user_query):
    kst = pytz.timezone("Asia/Seoul")
    current_datetime = datetime.now(timezone.utc).astimezone(kst)
    base_date = current_datetime.strftime("%Y%m%d")
    current_hour = current_datetime.strftime("%H")

    messages = [
        {"role": "system", "content": f"""
            ë‹¹ì‹ ì€ ì£¼ì°¨ì¥ ì§ˆë¬¸ì—ì„œ í•µì‹¬ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
            
            ì£¼ì°¨ì¥ ìœ„ì¹˜ í‚¤ì›Œë“œ:
            - "T1", "í„°ë¯¸ë„1", "1í„°ë¯¸ë„" â†’ "T1"
            - "T2", "í„°ë¯¸ë„2", "2í„°ë¯¸ë„" â†’ "T2"  
            - "ë‹¨ê¸°", "ë‹¨ê¸°ì£¼ì°¨ì¥" â†’ "ë‹¨ê¸°ì£¼ì°¨ì¥"
            - "ì¥ê¸°", "ì¥ê¸°ì£¼ì°¨ì¥" â†’ "ì¥ê¸°ì£¼ì°¨ì¥"
            - "ì§€ìƒ", "ì§€ìƒì¸µ" â†’ "ì§€ìƒì¸µ"
            - "ì§€í•˜", "ì§€í•˜ì¸µ" â†’ "ì§€í•˜ì¸µ"
            
            ì‹œê°„ ì •ë³´:
            - "ì§€ê¸ˆ", "í˜„ì¬" â†’ "{current_hour}"
            - "ì˜¤ì „", "AM" â†’ "0X" í˜•íƒœ
            - "ì˜¤í›„", "PM" â†’ "1X" í˜•íƒœ
            
            í˜„ì¬ ë‚ ì§œ: {base_date}
            í˜„ì¬ ì‹œê°„: {current_hour}
            
            JSONìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”. í™•ì‹¤í•˜ì§€ ì•Šì€ ì •ë³´ëŠ” nullë¡œ ì„¤ì •í•˜ì„¸ìš”.
            
            ì˜ˆì‹œ:
            {{"floor_keywords": ["T1", "ë‹¨ê¸°ì£¼ì°¨ì¥", "ì§€ìƒì¸µ"], "date": "{base_date}", "time": "{current_hour}"}}
        """},
        {"role": "user", "content": user_query}
    ]

    res = openai_client.chat.completions.create(
        model=OPENAI_GPT_MODEL,
        messages=messages,
        response_format={"type": "json_object"},
        temperature=0.1
    )

    return res.choices[0].message.content

def query_similar_parking_data(user_query, entities, top_k=10):
    # ì„ë² ë”© ìƒì„±
    embedding_res = openai_client.embeddings.create(
        input=user_query,
        model=AZURE_OPENAI_DEPLOYMENT
    )
    query_vector = embedding_res.data[0].embedding

    # ê¸°ë³¸ ë²¡í„° ê²€ìƒ‰ (í•„í„°ë§ ì—†ìŒ)
    base_query = f"""
    SELECT TOP {top_k}
        c.floor, c.parking_count, c.parking_total,
        c.congestion_rate, c.congestion_level, c.date, c.time,
        VectorDistance(c.embedding, @query_vector) as similarity_score
    FROM c
    WHERE IS_DEFINED(c.embedding)
    ORDER BY VectorDistance(c.embedding, @query_vector)
    """
    
    parameters = [{"name": "@query_vector", "value": query_vector}]
    
    try:
        results = list(parking_container.query_items(
            query=base_query,
            parameters=parameters,
            enable_cross_partition_query=True
        ))
        
        logging.info(f"ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ ìˆ˜: {len(results)}")
        
        # ì—”í‹°í‹° ê¸°ë°˜ í›„ì²˜ë¦¬ í•„í„°ë§
        if entities and results:
            filtered_results = []
            floor_keywords = entities.get("floor_keywords", [])
            target_date = entities.get("date")
            target_time = entities.get("time")
            
            for result in results:
                score = 0
                
                # ìœ„ì¹˜ í‚¤ì›Œë“œ ë§¤ì¹­ (ë¶€ë¶„ ì¼ì¹˜)
                if floor_keywords:
                    floor_text = result.get("floor", "").upper()
                    for keyword in floor_keywords:
                        if keyword.upper() in floor_text:
                            score += 2
                
                # ë‚ ì§œ ë§¤ì¹­
                if target_date and str(result.get("date", "")) == str(target_date):
                    score += 1
                
                # ì‹œê°„ ë§¤ì¹­ (1ì‹œê°„ ë²”ìœ„)
                if target_time and result.get("time"):
                    result_hour = int(result["time"].split(":")[0])
                    target_hour = int(target_time)
                    if abs(result_hour - target_hour) <= 1:
                        score += 1
                
                result["relevance_score"] = score
                filtered_results.append(result)
            
            # ê´€ë ¨ì„± ì ìˆ˜ë¡œ ì •ë ¬
            filtered_results.sort(key=lambda x: (x["relevance_score"], -x["similarity_score"]), reverse=True)
            
            return filtered_results[:top_k//2] if filtered_results else results[:top_k//2]
        
        return results
        
    except Exception as e:
        logging.error(f"ë²¡í„° ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}")
        return fallback_search(entities)

def fallback_search(entities):
    try:
        where_clauses = []
        parameters = []
        
        if entities and entities.get("floor_keywords"):
            floor_conditions = []
            for i, keyword in enumerate(entities["floor_keywords"]):
                param_name = f"@floor_keyword_{i}"
                floor_conditions.append(f"CONTAINS(UPPER(c.floor), UPPER({param_name}))")
                parameters.append({"name": param_name, "value": keyword})
            
            if floor_conditions:
                where_clauses.append(f"({' OR '.join(floor_conditions)})")
        
        if entities and entities.get("date"):
            where_clauses.append("c.date = @date")
            parameters.append({"name": "@date", "value": int(entities["date"])})
        
        where_sql = " AND ".join(where_clauses) if where_clauses else "1=1"
        
        query = f"""
        SELECT TOP 5
            c.floor, c.parking_count, c.parking_total,
            c.congestion_rate, c.congestion_level, c.date, c.time
        FROM c
        WHERE {where_sql}
        ORDER BY c.date DESC, c.time DESC
        """
        
        results = list(parking_container.query_items(
            query=query,
            parameters=parameters,
            enable_cross_partition_query=True
        ))
        
        logging.info(f"Fallback ê²€ìƒ‰ ê²°ê³¼ ìˆ˜: {len(results)}")
        return results
        
    except Exception as e:
        logging.error(f"Fallback ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}")
        return []

# ì‹œì„¤ ê´€ë ¨ í•¨ìˆ˜ë“¤ ê°œì„ 
def query_facility_data(user_query, top_k=10):
    """ê³µí•­ ì‹œì„¤ ì •ë³´ ê²€ìƒ‰ - ë” ë§ì€ ê²°ê³¼ ë°˜í™˜"""
    try:
        # ì„ë² ë”© ìƒì„±
        embedding_res = openai_client.embeddings.create(
            input=user_query,
            model=AZURE_OPENAI_DEPLOYMENT
        )
        query_vector = embedding_res.data[0].embedding
        
        # ë²¡í„° ê²€ìƒ‰
        query = f"""
        SELECT TOP {top_k}
            c.entrpskoreannm, c.trtmntprdlstkoreannm, c.lckoreannm,
            c.servicetime, c.arrordep, c.tel,
            VectorDistance(c.embedding, @query_vector) as similarity_score
        FROM c
        WHERE IS_DEFINED(c.embedding)
        ORDER BY VectorDistance(c.embedding, @query_vector)
        """
        
        parameters = [{"name": "@query_vector", "value": query_vector}]
        
        results = list(facility_container.query_items(
            query=query,
            parameters=parameters,
            enable_cross_partition_query=True
        ))
        
        logging.info(f"ì‹œì„¤ ê²€ìƒ‰ ê²°ê³¼ ìˆ˜: {len(results)}")
        
        # í‚¤ì›Œë“œ ê¸°ë°˜ í›„ì²˜ë¦¬ í•„í„°ë§ ì¶”ê°€
        if results and user_query:
            filtered_results = []
            query_keywords = user_query.lower().split()
            
            for result in results:
                score = result.get('similarity_score', 0)
                
                # í‚¤ì›Œë“œ ë§¤ì¹­ìœ¼ë¡œ ì ìˆ˜ ë³´ì •
                facility_text = f"{result.get('entrpskoreannm', '')} {result.get('trtmntprdlstkoreannm', '')} {result.get('lckoreannm', '')}".lower()
                
                for keyword in query_keywords:
                    if keyword in facility_text:
                        score += 0.1  # í‚¤ì›Œë“œ ë§¤ì¹­ ë³´ë„ˆìŠ¤
                
                result['adjusted_score'] = score
                filtered_results.append(result)
            
            # ì¡°ì •ëœ ì ìˆ˜ë¡œ ì •ë ¬
            filtered_results.sort(key=lambda x: x['adjusted_score'])
            return filtered_results
        
        return results
        
    except Exception as e:
        logging.error(f"ì‹œì„¤ ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}")
        return []

# í•­ê³µí¸ ê´€ë ¨ í•¨ìˆ˜ë“¤ ëŒ€í­ ê°œì„ 
def query_flight_data(user_query, flight_number=None, top_k=10):
    """í•­ê³µí¸ ì •ë³´ ê²€ìƒ‰ - ê°œì„ ëœ ë²„ì „"""
    try:
        # í•­ê³µí¸ ë²ˆí˜¸ê°€ ìˆìœ¼ë©´ ìš°ì„  ì •í™•í•œ ë§¤ì¹­ ì‹œë„
        if flight_number:
            logging.info(f"í•­ê³µí¸ ë²ˆí˜¸ë¡œ ê²€ìƒ‰ ì‹œë„: {flight_number}")
            
            # ì •í™•í•œ ë§¤ì¹­ ì‹œë„
            exact_query = """
            SELECT TOP 20
                c.date, c.hr, c.min, c.yoil, c.airline, c.flightid,
                c.scheduleDateTime, c.estimatedDateTime, c.airport, c.remark,
                c.gatenumber, c.temp, c.senstemp, c.himidity, c.wind
            FROM c
            WHERE UPPER(c.flightid) = UPPER(@flight_number)
            ORDER BY c.date DESC, c.hr DESC, c.min DESC
            """
            
            exact_params = [{"name": "@flight_number", "value": flight_number}]
            
            try:
                exact_results = list(flight_container.query_items(
                    query=exact_query,
                    parameters=exact_params,
                    enable_cross_partition_query=True
                ))
                
                logging.info(f"ì •í™•í•œ í•­ê³µí¸ ë§¤ì¹­ ê²°ê³¼ ìˆ˜: {len(exact_results)}")
                
                if exact_results:
                    return exact_results
                else:
                    # ë¶€ë¶„ ë§¤ì¹­ ì‹œë„
                    partial_query = """
                    SELECT TOP 20
                        c.date, c.hr, c.min, c.yoil, c.airline, c.flightid,
                        c.scheduleDateTime, c.estimatedDateTime, c.airport, c.remark,
                        c.gatenumber, c.temp, c.senstemp, c.himidity, c.wind
                    FROM c
                    WHERE CONTAINS(UPPER(c.flightid), UPPER(@flight_number))
                    ORDER BY c.date DESC, c.hr DESC, c.min DESC
                    """
                    
                    partial_results = list(flight_container.query_items(
                        query=partial_query,
                        parameters=exact_params,
                        enable_cross_partition_query=True
                    ))
                    
                    logging.info(f"ë¶€ë¶„ í•­ê³µí¸ ë§¤ì¹­ ê²°ê³¼ ìˆ˜: {len(partial_results)}")
                    
                    if partial_results:
                        return partial_results
                    
            except Exception as e:
                logging.error(f"í•­ê³µí¸ ì§ì ‘ ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}")
        
        # ë²¡í„° ê²€ìƒ‰ ì‹œë„
        logging.info("í•­ê³µí¸ ë²¡í„° ê²€ìƒ‰ ì‹œë„")
        
        embedding_res = openai_client.embeddings.create(
            input=user_query,
            model=AZURE_OPENAI_DEPLOYMENT
        )
        query_vector = embedding_res.data[0].embedding
        
        vector_query = f"""
        SELECT TOP {top_k}
            c.date, c.hr, c.min, c.yoil, c.airline, c.flightid,
            c.scheduleDateTime, c.estimatedDateTime, c.airport, c.remark,
            c.gatenumber, c.temp, c.senstemp, c.himidity, c.wind,
            VectorDistance(c.embedding, @query_vector) as similarity_score
        FROM c
        WHERE IS_DEFINED(c.embedding)
        ORDER BY VectorDistance(c.embedding, @query_vector)
        """
        
        vector_params = [{"name": "@query_vector", "value": query_vector}]
        
        results = list(flight_container.query_items(
            query=vector_query,
            parameters=vector_params,
            enable_cross_partition_query=True
        ))
        
        logging.info(f"í•­ê³µí¸ ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ ìˆ˜: {len(results)}")
        return results
        
    except Exception as e:
        logging.error(f"í•­ê³µí¸ ê²€ìƒ‰ ì „ì²´ ì˜¤ë¥˜: {str(e)}")
        return []

# í†µí•© ì‘ë‹µ ìƒì„± í•¨ìˆ˜ ê°œì„ 
def generate_comprehensive_response(user_query, category, flight_number=None):
    """ì¹´í…Œê³ ë¦¬ì— ë”°ë¥¸ í†µí•© ì‘ë‹µ ìƒì„±"""
    try:
        context_parts = []
        
        # ì£¼ì°¨ì¥ ì •ë³´ê°€ í•„ìš”í•œ ê²½ìš°
        if category in ["parking", "mixed"]:
            entities_str = get_entities(user_query)
            try:
                entities = json.loads(entities_str)
            except:
                entities = {}
            
            parking_data = query_similar_parking_data(user_query, entities)
            if parking_data:
                context_parts.append("ğŸš— ì£¼ì°¨ì¥ í˜„í™©:")
                for i, item in enumerate(parking_data[:3], 1):
                    available = item['parking_total'] - item['parking_count']
                    context_parts.append(
                        f"{i}. {item['floor']} - "
                        f"í˜¼ì¡ë„: {item['congestion_level']}({item['congestion_rate']}%), "
                        f"ì”ì—¬: {available}ëŒ€"
                    )
        
        # ì‹œì„¤ ì •ë³´ê°€ í•„ìš”í•œ ê²½ìš° - ë” ë§ì€ ê²°ê³¼ í‘œì‹œ
        if category in ["facility", "mixed", "general"]:
            facility_data = query_facility_data(user_query, top_k=15)
            if facility_data:
                context_parts.append("\nğŸ¢ ê³µí•­ ì‹œì„¤ ì •ë³´:")
                # ìµœëŒ€ 8ê°œê¹Œì§€ í‘œì‹œ (ê¸°ì¡´ 3ê°œì—ì„œ ì¦ê°€)
                for i, item in enumerate(facility_data[:8], 1):
                    location = item.get('lckoreannm', '')
                    service_time = item.get('servicetime', '')
                    tel = item.get('tel', '')
                    arrordep = item.get('arrordep', '')
                    
                    context_parts.append(
                        f"{i}. {item.get('entrpskoreannm', '')}\n"
                        f"   â€¢ ì„œë¹„ìŠ¤: {item.get('trtmntprdlstkoreannm', '')}\n"
                        f"   â€¢ ìœ„ì¹˜: {location}\n"
                        f"   â€¢ êµ¬ë¶„: {arrordep}\n"
                        f"   â€¢ ìš´ì˜ì‹œê°„: {service_time}\n"
                        f"   â€¢ ì—°ë½ì²˜: {tel}"
                    )
        
        # í•­ê³µí¸ ì •ë³´ê°€ í•„ìš”í•œ ê²½ìš°
        if category in ["flight", "mixed"] or flight_number:
            flight_data = query_flight_data(user_query, flight_number)
            if flight_data:
                context_parts.append("\nâœˆï¸ í•­ê³µí¸ ì •ë³´:")
                for i, item in enumerate(flight_data[:5], 1):
                    weather_info = ""
                    if item.get('temp'):
                        weather_info = f"ë‚ ì”¨: {item['temp']}Â°C (ì²´ê° {item.get('senstemp', 'N/A')}Â°C), ìŠµë„: {item.get('himidity', 'N/A')}%"
                    
                    context_parts.append(
                        f"{i}. {item.get('airline', '')} {item.get('flightid', '')}\n"
                        f"   â€¢ ëª©ì ì§€: {item.get('airport', '')}\n"
                        f"   â€¢ ë‚ ì§œ: {item.get('date', '')} ({item.get('yoil', '')})\n"
                        f"   â€¢ ì˜ˆì •ì‹œê°„: {item.get('scheduleDateTime', '')}\n"
                        f"   â€¢ ì˜ˆìƒì‹œê°„: {item.get('estimatedDateTime', '')}\n"
                        f"   â€¢ ê²Œì´íŠ¸: {item.get('gatenumber', '')}\n"
                        f"   â€¢ êµ¬ë¶„: {item.get('remark', '')}\n"
                        f"   â€¢ {weather_info}"
                    )
            else:
                context_parts.append("\nâœˆï¸ í•­ê³µí¸ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                if flight_number:
                    context_parts.append(f"ê²€ìƒ‰í•œ í•­ê³µí¸ ë²ˆí˜¸: {flight_number}")
        
        # ì»¨í…ìŠ¤íŠ¸ ì¡°í•©
        context = "\n".join(context_parts) if context_parts else "ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        # GPT ì‘ë‹µ ìƒì„±
        system_prompt = """
        ë‹¹ì‹ ì€ ì¸ì²œêµ­ì œê³µí•­ì˜ ì¢…í•© ì•ˆë‚´ ì±—ë´‡ì…ë‹ˆë‹¤.
        
        ì—­í• :
        1. ì£¼ì°¨ì¥ ì •ë³´ (í˜¼ì¡ë„, ì”ì—¬ê³µê°„ ë“±) ì•ˆë‚´
        2. ê³µí•­ ì‹œì„¤ (í™˜ì „ì†Œ, ì‹ë‹¹, í¸ì˜ì‹œì„¤ ë“±) ì•ˆë‚´ - ê°€ëŠ¥í•œ ë§ì€ ì˜µì…˜ ì œê³µ
        3. í•­ê³µí¸ ì •ë³´ (ì¶œë°œ/ë„ì°© ì‹œê°„, ê²Œì´íŠ¸, ë‚ ì”¨ ë“±) ì•ˆë‚´
        4. ì—¬í–‰ ì¤€ë¹„ë¬¼ ë° ê³µí•­ ì´ìš© íŒ ì œê³µ
        
        ì‘ë‹µ ê°€ì´ë“œë¼ì¸:
        - ì¹œì ˆí•˜ê³  ë„ì›€ì´ ë˜ëŠ” í†¤ìœ¼ë¡œ ë‹µë³€
        - êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ì •ë³´ ì œê³µ
        - ì´ëª¨ì§€ë¥¼ ì ì ˆíˆ ì‚¬ìš©í•˜ì—¬ ê°€ë…ì„± í–¥ìƒ
        - ì‚¬ìš©ìì˜ êµ¬ì²´ì ì¸ ìƒí™©ì„ ê³ ë ¤í•œ ë§ì¶¤í˜• ë‹µë³€
        - ì‹œì„¤ ì •ë³´ ìš”ì²­ì‹œ ê°€ëŠ¥í•œ ë§ì€ ì˜µì…˜ì„ ì œê³µí•˜ì—¬ ì„ íƒì˜ í­ì„ ë„“í˜€ì£¼ì„¸ìš”
        - í•­ê³µí¸ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš° ëª…í™•íˆ ì•ˆë‚´í•´ì£¼ì„¸ìš”
        - ì¶”ê°€ì ì¸ íŒì´ë‚˜ ì£¼ì˜ì‚¬í•­ì´ ìˆìœ¼ë©´ í•¨ê»˜ ì œê³µ
        """
        
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": f"ì§ˆë¬¸: {user_query}\n\nê´€ë ¨ ì •ë³´:\n{context}"}
        ]
        
        response = openai_client.chat.completions.create(
            model=OPENAI_GPT_MODEL,
            messages=messages,
            temperature=0.3,
            max_tokens=1500  # í† í° ìˆ˜ ì¦ê°€
        )
        
        return response.choices[0].message.content
        
    except Exception as e:
        logging.error(f"í†µí•© ì‘ë‹µ ìƒì„± ì˜¤ë¥˜: {str(e)}")
        return f"ì£„ì†¡í•©ë‹ˆë‹¤. ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

# ê¸°ì¡´ ì£¼ì°¨ì¥ ì „ìš© í•¨ìˆ˜ (í•˜ìœ„ í˜¸í™˜ì„± ìœ ì§€)
def generate_parking_response(user_query):
    """ì£¼ì°¨ì¥ ì „ìš© ì‘ë‹µ ìƒì„± (ê¸°ì¡´ í˜¸í™˜ì„± ìœ ì§€)"""
    return generate_comprehensive_response(user_query, "parking")

# Static Web Appìš© ë©”ì¸ í•¨ìˆ˜
async def main(req: func.HttpRequest) -> func.HttpResponse:
    """Static Web Appì—ì„œ í˜¸ì¶œë˜ëŠ” ë©”ì¸ í•¨ìˆ˜"""
    
    # CORS í—¤ë” ì„¤ì •
    headers = {
        "Access-Control-Allow-Origin": "*",
        "Access-Control-Allow-Methods": "GET, POST, OPTIONS",
        "Access-Control-Allow-Headers": "Content-Type, Authorization"
    }
    
    try:
        # OPTIONS ìš”ì²­ ì²˜ë¦¬ (CORS preflight)
        if req.method == "OPTIONS":
            return func.HttpResponse(
                "",
                headers=headers,
                status_code=200
            )
        
        # POST ìš”ì²­ë§Œ ì²˜ë¦¬
        if req.method != "POST":
            return func.HttpResponse(
                json.dumps({"status": "error", "message": "POST ìš”ì²­ë§Œ ì§€ì›ë©ë‹ˆë‹¤"}),
                mimetype=APPLICATION_JSON,
                headers=headers,
                status_code=405
            )
        
        # ìš”ì²­ ë³¸ë¬¸ íŒŒì‹±
        body = req.get_json()
        if not body or "question" not in body:
            return func.HttpResponse(
                json.dumps({"status": "error", "message": "ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”"}),
                mimetype=APPLICATION_JSON,
                headers=headers,
                status_code=400
            )
        
        question = body.get("question", "").strip()
        if not question:
            return func.HttpResponse(
                json.dumps({"status": "error", "message": "ì§ˆë¬¸ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤"}),
                mimetype=APPLICATION_JSON,
                headers=headers,
                status_code=400
            )
        
        logging.info(f"ì§ˆë¬¸ ìˆ˜ì‹ : {question}")
        
        # ì§ˆë¬¸ ë¶„ë¥˜
        classification = classify_question(question)
        category = classification.get("category", "general")
        flight_number = classification.get("flight_number")
        
        logging.info(f"ë¶„ë¥˜ëœ ì¹´í…Œê³ ë¦¬: {category}, í•­ê³µí¸ ë²ˆí˜¸: {flight_number}")
        
        # í†µí•© ì‘ë‹µ ìƒì„±
        answer = generate_comprehensive_response(question, category, flight_number)
        
        return func.HttpResponse(
            json.dumps({
                "status": "success", 
                "answer": answer,
                "category": category,
                "flight_number": flight_number,
                "timestamp": datetime.now(timezone.utc).isoformat()
            }, ensure_ascii=False),
            mimetype=APPLICATION_JSON,
            headers=headers,
            status_code=200
        )

    except Exception as e:
        logging.error(f"ì „ì²´ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
        return func.HttpResponse(
            json.dumps({
                "status": "error", 
                "message": "ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤",
                "error_detail": str(e)
            }),
            mimetype=APPLICATION_JSON,
            headers=headers,
            status_code=500
        )
